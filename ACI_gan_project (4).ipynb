{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75_LC4sfnWlL",
        "outputId": "8c524c77-369e-4ef8-a230-466eb1f4bf13",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install pandas numpy scikit-learn imbalanced-learn mlxtend tensorflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU, Input\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORRECTED CODE**"
      ],
      "metadata": {
        "id": "h1xyVdWx60h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NUwN6bTAHSb",
        "outputId": "cbd165fe-aaf5-44af-c97f-65c49ab08544"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU detected. Running on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "print(\"Dataset loaded successfully. Shape:\", data.shape)\n",
        "\n",
        "# Handle Missing Values\n",
        "print(\"Handling missing values...\")\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "print(\"Missing values filled.\")\n",
        "\n",
        "# Encode Target Variable\n",
        "print(\"Encoding target variable...\")\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])\n",
        "print(\"Target variable encoded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVjjYP3fAMGW",
        "outputId": "e4509c5f-3b55-4df7-b279-9b19af2d61b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully. Shape: (286, 10)\n",
            "Handling missing values...\n",
            "Missing values filled.\n",
            "Encoding target variable...\n",
            "Target variable encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "print(\"Feature encoding completed. Shape:\", X_encoded.shape)\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "print(\"Applying SMOTE for data balancing...\")\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "print(\"SMOTE applied. Balanced dataset shape:\", X_smote.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pkYfmFHAQQ1",
        "outputId": "61797fcd-3f54-43c2-9360-a610daa851a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature encoding completed. Shape: (286, 41)\n",
            "Applying SMOTE for data balancing...\n",
            "SMOTE applied. Balanced dataset shape: (402, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "print(\"Building GAN models...\")\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"GAN models built successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpJHazjC2ZA",
        "outputId": "0de7b3fb-d710-4ef2-a300-e72a4797709a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building GAN models...\n",
            "GAN models built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(epochs=1000, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    print(\"Starting GAN training...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "print(\"Training GAN...\")\n",
        "train_gan()\n",
        "print(\"GAN training completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzfIKre3AU0c",
        "outputId": "4eb136fb-4163-4f2b-9c1b-d22079ca44dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GAN...\n",
            "Starting GAN training...\n",
            "Epoch 0: D Loss Real: 0.5991918444633484, D Loss Fake: 0.730866551399231, GAN Loss: [array(0.67911226, dtype=float32), array(0.6666667, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.4827026128768921, D Loss Fake: 0.4833218455314636, GAN Loss: [array(0.48412365, dtype=float32), array(0.6596535, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.4742725193500519, D Loss Fake: 0.4746403992176056, GAN Loss: [array(0.47500798, dtype=float32), array(0.6565091, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.4711625874042511, D Loss Fake: 0.4714067280292511, GAN Loss: [array(0.47166073, dtype=float32), array(0.65545404, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.4694405496120453, D Loss Fake: 0.4696372449398041, GAN Loss: [array(0.46981698, dtype=float32), array(0.65430176, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.46835121512413025, D Loss Fake: 0.4684966206550598, GAN Loss: [array(0.4686529, dtype=float32), array(0.65427476, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.4675828218460083, D Loss Fake: 0.4677063524723053, GAN Loss: [array(0.46783498, dtype=float32), array(0.6535635, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.4670059382915497, D Loss Fake: 0.467120498418808, GAN Loss: [array(0.46722367, dtype=float32), array(0.65275794, dtype=float32)]\n",
            "Epoch 800: D Loss Real: 0.4665658473968506, D Loss Fake: 0.46666231751441956, GAN Loss: [array(0.46675614, dtype=float32), array(0.6516854, dtype=float32)]\n",
            "Epoch 900: D Loss Real: 0.46620944142341614, D Loss Fake: 0.46629661321640015, GAN Loss: [array(0.466379, dtype=float32), array(0.6506197, dtype=float32)]\n",
            "GAN training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Performing Association Rule Mining using Apriori algorithm...\")\n",
        "\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "print(\"Association Rule Mining completed. Rules found:\", rules.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyg22dv_Aa8t",
        "outputId": "57da5747-02cb-4ac3-c3e6-d7e1a69203ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing Association Rule Mining using Apriori algorithm...\n",
            "Association Rule Mining completed. Rules found: 388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Random Forest Classifier with GridSearchCV...\")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_ziM47Adg7",
        "outputId": "98ae6bc1-7128-40d3-faf4-541fe342e663"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier with GridSearchCV...\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82        41\n",
            "           1       0.84      0.78      0.81        40\n",
            "\n",
            "    accuracy                           0.81        81\n",
            "   macro avg       0.82      0.81      0.81        81\n",
            "weighted avg       0.82      0.81      0.81        81\n",
            "\n",
            "ROC-AUC Score: 0.9030487804878049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    print(\"Prediction:\", result, \"| Confidence:\", confidence)\n",
        "    return result, confidence\n"
      ],
      "metadata": {
        "id": "09ngXo-fAheK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE INPUTS"
      ],
      "metadata": {
        "id": "0QCXsS-m9YNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "example_input = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMfQn98q-UVt",
        "outputId": "190b9192-f3a0-41e5-c045-2a669bf78c62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.30892742021745634\n",
            "Prediction: No Cancer Detected, Confidence: 0.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '50-54', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'right', 'Breast-quad': 'right_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OajJG4tF1MUq",
        "outputId": "0fcaba51-5309-476c-8a9c-64150d4142e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.812765444015444\n",
            "Prediction: Cancer Detected, Confidence: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '60-69', 'Menopause': 'ge-40', 'Tumor-size': '15-19', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "#60-69,ge40,15-19,0-2,no,2,right,left_up,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQEgIbUG8KnM",
        "outputId": "2ebcba9b-32fe-41f2-dc6b-9905f53a5c76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.21254086798890662\n",
            "Prediction: No Cancer Detected, Confidence: 0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '20-24', 'Inv-nodes': '3-5',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 2,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "#30-39,premeno,20-24,3-5,yes,2,left,left_low,no\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXoFmT0y8Myl",
        "outputId": "010b2b4f-9180-410b-9293-3e8d4eef204e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.7175413678379087\n",
            "Prediction: Cancer Detected, Confidence: 0.72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30-39,premeno,0-4,0-2,no,2,right,central,no\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '0-4', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2,'Breast': 'right', 'Breast-quad': 'central', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "id": "gVSXbMYP81dF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d3fb8a-1a00-4719-a829-16cb585feff5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: No Cancer Detected | Confidence: 0.4068955988071309\n",
            "Prediction: No Cancer Detected, Confidence: 0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#50-59,ge40,40-44,6-8,yes,3,left,left_low,yes\n",
        "example_input = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '40-44', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3,'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbhyWrpoAnjw",
        "outputId": "f7e80a59-b6e8-4103-f3ff-30da42bd82ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer Detected | Confidence: 0.951515444015444\n",
            "Prediction: Cancer Detected, Confidence: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FULL CODE**"
      ],
      "metadata": {
        "id": "4v9Cc6n8AnJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle Missing Values\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "\n",
        "# Encode Target Variable\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])  # Encode target variable\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Balance Dataset using SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "X_smote, y_smote = smote.fit_resample(X_encoded, y)\n",
        "\n",
        "# GAN for Data Augmentation\n",
        "def build_generator(input_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(128),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(64),\n",
        "        LeakyReLU(negative_slope=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "generator = build_generator(X_smote.shape[1], X_smote.shape[1])\n",
        "discriminator = build_discriminator(X_smote.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train GAN with TensorFlow context\n",
        "def train_gan(epochs=800, batch_size=8):  # Reduced batch size for memory efficiency\n",
        "    tf.keras.backend.clear_session()  # Reset session before training\n",
        "    for epoch in range(epochs):\n",
        "        noise = np.random.normal(0, 1, (batch_size, X_smote.shape[1]))\n",
        "        generated_data = generator(noise, training=True)\n",
        "\n",
        "        real_indices = np.random.randint(0, X_smote.shape[0], batch_size)\n",
        "        real_data = X_smote.iloc[real_indices].values.astype(np.float32)  # Ensure TensorFlow compatible format\n",
        "        labels_real = np.ones((batch_size, 1))\n",
        "        labels_fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_data, labels_real)\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_data, labels_fake)\n",
        "\n",
        "        gan_loss = discriminator.train_on_batch(generated_data, labels_real)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}: D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, GAN Loss: {gan_loss}\")\n",
        "\n",
        "train_gan()\n",
        "\n",
        "# Association Rule Mining with Apriori\n",
        "data_apriori = X_smote.astype(bool)  # Convert to True/False (1/0)\n",
        "\n",
        "frequent_itemsets = apriori(data_apriori, min_support=0.15, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.75)\n",
        "\n",
        "# Enhanced Classification Model with Random Forest & Grid Search\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Cancer Detected\" if prediction[0] == 1 else \"No Cancer Detected\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    return result, confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f85vImWBArbw",
        "outputId": "7642ced4-c3c9-4c6e-bc4c-c4595fe7cdc5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: D Loss Real: 0.6595611572265625, D Loss Fake: 0.6818803548812866, GAN Loss: [array(0.69481295, dtype=float32), array(0.5, dtype=float32)]\n",
            "Epoch 100: D Loss Real: 0.48659488558769226, D Loss Fake: 0.4872722625732422, GAN Loss: [array(0.4879854, dtype=float32), array(0.65470296, dtype=float32)]\n",
            "Epoch 200: D Loss Real: 0.47736144065856934, D Loss Fake: 0.47774970531463623, GAN Loss: [array(0.47809216, dtype=float32), array(0.6573383, dtype=float32)]\n",
            "Epoch 300: D Loss Real: 0.47350695729255676, D Loss Fake: 0.47374868392944336, GAN Loss: [array(0.4740036, dtype=float32), array(0.65808415, dtype=float32)]\n",
            "Epoch 400: D Loss Real: 0.47137847542762756, D Loss Fake: 0.47156044840812683, GAN Loss: [array(0.47175127, dtype=float32), array(0.6561721, dtype=float32)]\n",
            "Epoch 500: D Loss Real: 0.47007322311401367, D Loss Fake: 0.47023552656173706, GAN Loss: [array(0.47037473, dtype=float32), array(0.65568864, dtype=float32)]\n",
            "Epoch 600: D Loss Real: 0.4690990746021271, D Loss Fake: 0.4692196547985077, GAN Loss: [array(0.46935004, dtype=float32), array(0.65439546, dtype=float32)]\n",
            "Epoch 700: D Loss Real: 0.4683550000190735, D Loss Fake: 0.4684636890888214, GAN Loss: [array(0.4685704, dtype=float32), array(0.653709, dtype=float32)]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85        41\n",
            "           1       0.85      0.85      0.85        40\n",
            "\n",
            "    accuracy                           0.85        81\n",
            "   macro avg       0.85      0.85      0.85        81\n",
            "weighted avg       0.85      0.85      0.85        81\n",
            "\n",
            "ROC-AUC Score: 0.9060975609756098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "recurrent and non-recurrent\n"
      ],
      "metadata": {
        "id": "Kyx5lxW0LpDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from imblearn.combine import SMOTETomek\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, LeakyReLU\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"  # Prevents memory allocation issues\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU if GPU issues exist\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Load dataset from UCI URL\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer/breast-cancer.data\"\n",
        "column_names = ['Class', 'Age', 'Menopause', 'Tumor-size', 'Inv-nodes', 'Node-caps', 'Deg-malig',\n",
        "                'Breast', 'Breast-quad', 'Irradiat']\n",
        "data = pd.read_csv(url, names=column_names, na_values='?')\n",
        "\n",
        "# Handle Missing Values\n",
        "data.fillna(data.mode().iloc[0], inplace=True)\n",
        "\n",
        "# Encode Target Variable for Recurrent vs. Non-Recurrent Classification\n",
        "target_encoder = LabelEncoder()\n",
        "data['Class'] = target_encoder.fit_transform(data['Class'])  # 0: Non-Recurrent, 1: Recurrent\n",
        "\n",
        "# Separate Features and Target\n",
        "X = data.drop(columns=['Class'])\n",
        "y = data['Class']\n",
        "\n",
        "# One-Hot Encode Categorical Variables\n",
        "categorical_features = X.columns.tolist()\n",
        "preprocessor = ColumnTransformer([('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "X_encoded = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense array\n",
        "\n",
        "# Convert Encoded Features to DataFrame\n",
        "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Balance Dataset using SMOTETomek\n",
        "smote_tomek = SMOTETomek(sampling_strategy='auto')\n",
        "X_smote, y_smote = smote_tomek.fit_resample(X_encoded, y)\n",
        "\n",
        "# Enhanced Classification Model with Random Forest & Grid Search\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {'classifier__n_estimators': [100, 200, 300], 'classifier__max_depth': [10, 20, 30]}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=10, scoring='f1', n_jobs=-1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, stratify=y_smote, test_size=0.2, random_state=42)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "y_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# Prediction Function\n",
        "def predict_cancer(input_data):\n",
        "    input_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "\n",
        "    # Apply the same preprocessing used for training\n",
        "    input_encoded = preprocessor.transform(input_df).toarray()\n",
        "    input_encoded = pd.DataFrame(input_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "    # Ensure all features match training data\n",
        "    missing_cols = set(X_smote.columns) - set(input_encoded.columns)\n",
        "    for col in missing_cols:\n",
        "        input_encoded[col] = 0  # Add missing columns with zero\n",
        "\n",
        "    input_encoded = input_encoded[X_smote.columns]  # Ensure correct column order\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = grid.best_estimator_.predict(input_encoded)\n",
        "    prediction_proba = grid.best_estimator_.predict_proba(input_encoded)[:, 1]\n",
        "\n",
        "    result = \"Recurrent Breast Cancer\" if prediction[0] == 1 else \"Non-Recurrent Breast Cancer\"\n",
        "    confidence = prediction_proba[0]\n",
        "\n",
        "    return result, confidence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk1I9ci8LrnN",
        "outputId": "d390b15b-a8c7-4bbb-f773-3048e19be139"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83        41\n",
            "           1       0.84      0.80      0.82        40\n",
            "\n",
            "    accuracy                           0.83        81\n",
            "   macro avg       0.83      0.83      0.83        81\n",
            "weighted avg       0.83      0.83      0.83        81\n",
            "\n",
            "ROC-AUC Score: 0.9091463414634147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Non-Recurrent Case\n",
        "example_input_1 = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 2, 'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "# Example: Recurrent Case\n",
        "example_input_2 = {\n",
        "    'Age': '50-59', 'Menopause': 'ge40', 'Tumor-size': '50-54', 'Inv-nodes': '6-8',\n",
        "    'Node-caps': 'yes', 'Deg-malig': 3, 'Breast': 'right', 'Breast-quad': 'right_up', 'Irradiat': 'yes'\n",
        "}\n",
        "\n",
        "# Making Predictions\n",
        "result_1, confidence_1 = predict_cancer(example_input_1)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")\n",
        "\n",
        "result_2, confidence_2 = predict_cancer(example_input_2)\n",
        "print(f\"Prediction: {result_2}, Confidence: {confidence_2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fhy_EjqL2ud",
        "outputId": "2c11597d-835d-40f1-99b3-320ee015912d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Recurrent Breast Cancer, Confidence: 0.18\n",
            "Prediction: Recurrent Breast Cancer, Confidence: 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#no-recurrence-events,60-69,ge40,30-34,0-2,no,2,left,left_low,yes\n",
        "example_input_3 = {\n",
        "    'Age': '60-69', 'Menopause': 'ge40', 'Tumor-size': '30-34',\n",
        "    'Inv-nodes': '0-2','Node-caps': 'no', 'Deg-malig': 2,\n",
        "    'Breast': 'left', 'Breast-quad': 'left_low', 'Irradiat': 'yes'\n",
        "}\n",
        "result_1, confidence_1 = predict_cancer(example_input_1)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEOncxnWMDXD",
        "outputId": "3eaf0e2f-908b-45eb-f059-4fd12c515da0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Recurrent Breast Cancer, Confidence: 0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recurrence-events,40-49,premeno,30-34,3-5,no,2,right,left_up,no\n",
        "\n",
        "example_input_4 = {\n",
        "    'Age': '40-49', 'Menopause': 'premeno', 'Tumor-size': '30-34',\n",
        "    'Inv-nodes': '3-5','Node-caps': 'no', 'Deg-malig': 2,\n",
        "    'Breast': 'right', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "# Making Predictions\n",
        "result_1, confidence_1 = predict_cancer(example_input_4)\n",
        "print(f\"Prediction: {result_1}, Confidence: {confidence_1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dCSn8dTMb2Y",
        "outputId": "ad426f29-422a-4c08-eb0d-68b34288630d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Recurrent Breast Cancer, Confidence: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recurrence-events,30-39,premeno,40-44,0-2,no,1,left,left_up,no\n",
        "\n",
        "\n",
        "example_input = {\n",
        "    'Age': '30-39', 'Menopause': 'premeno', 'Tumor-size': '40-44', 'Inv-nodes': '0-2',\n",
        "    'Node-caps': 'no', 'Deg-malig': 1,'Breast': 'left', 'Breast-quad': 'left_up', 'Irradiat': 'no'\n",
        "}\n",
        "\n",
        "result, confidence = predict_cancer(example_input)\n",
        "print(f\"Prediction: {result}, Confidence: {confidence:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQFaZwxONXQG",
        "outputId": "9b0fdda7-8305-49c8-db17-dca991cec4ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Non-Recurrent Breast Cancer, Confidence: 0.49\n"
          ]
        }
      ]
    }
  ]
}